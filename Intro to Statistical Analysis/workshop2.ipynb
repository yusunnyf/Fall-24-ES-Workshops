{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZEsHr_LoOwN"
      },
      "source": [
        "# Intro to Statistical Analysis with Python\n",
        "\n",
        "**Date**: November 7th, 2024\n",
        "\n",
        "**Author**: Sunny Fang, yf2610\n",
        "\n",
        "_Created as part of the Barnard College Computing Fellows Program, Fall 2024_\n",
        "\n",
        "\n",
        "By the end of this workshop, students should be able to...\n",
        "1. Write well-documented, interpretable code for statistical testing,\n",
        "2. Interpret and explain statistical test results to an audience,\n",
        "3. Feel comfortable selecting and implementing the appropriate statistical test for their project,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIJhBHyboOwO"
      },
      "source": [
        "# 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q33BgRYYoOwO"
      },
      "outputs": [],
      "source": [
        "# %pip install pandas\n",
        "# %pip install seaborn\n",
        "# %pip install matplotlib\n",
        "# %pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J-IvxiF7oOwP"
      },
      "outputs": [],
      "source": [
        "# to process data\n",
        "import pandas as pd\n",
        "\n",
        "# for numerical processing\n",
        "import numpy as np\n",
        "\n",
        "# to plot data\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# to carry out statistical testing\n",
        "from scipy import stats\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# for datetime processing\n",
        "import datetime as dt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFZRp55doOwP"
      },
      "source": [
        "# 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_QdYR7AoOwP"
      },
      "source": [
        "Today, we are using an air pollution dataset from [Kaggle](https://www.kaggle.com/datasets/sogun3/uspollution/data).\n",
        "\n",
        "You can read the file with the following link: `https://drive.google.com/uc?id=1FNWe_pjSONfixgQHPz6o28tpg34Hiwvj`\n",
        "\n",
        "**IMPORTANT NOTE:** usually files end with .csv, but since we are reading a file from a Google Drive link, it looks a bit different here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwH-28JwoOwP"
      },
      "outputs": [],
      "source": [
        "# TODO: replace the filename\n",
        "# read the dataset using the link provided above\n",
        "df = pd.read_csv(\"_____\")\n",
        "\n",
        "# remove max column restriction\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "# display the first 5 rows\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3HyzEDUoOwP"
      },
      "outputs": [],
      "source": [
        "df_cols = df.columns.to_list()\n",
        "print(df_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5KcjyGuoOwP"
      },
      "outputs": [],
      "source": [
        "# Carry out basic data preprocessing techniques\n",
        "# step 1: drop NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# step 2: drop columns we don't need\n",
        "# TODO: keep everything *except for* the first 6 columns\n",
        "# i.e., we don't need: Unnamed: 0.1, Unnamed: 0, State Code,County Code, Site Num, and Address\n",
        "# there are several right answers to this!\n",
        "# df = df.iloc[:,6:]\n",
        "# df = df.drop(columns = ['Unnamed: 0.1', 'Unnamed: 0', 'State Code', 'County Code', 'Site Num', 'Address'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DE0J31ywoOwP"
      },
      "outputs": [],
      "source": [
        "# an important addition: as a good practice, when dealing with datetime objects in a dataframe,\n",
        "df['Date Local'] = pd.to_datetime(df['Date Local'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkAHa8lnoOwP"
      },
      "source": [
        "# 2. T-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2tDj7x4oOwP"
      },
      "source": [
        "### 2.1 One-sample T-test\n",
        "\n",
        "On October 1, 2015, the Environmental Protection Agency strengthend the National Ambient Air Quality Standards: \"areas will meet the standards if the 4th highest daily maximum 8-hour ozone concentration per year, averaged over three years, is **equal to or less than 70 ppb** (or 0.07 ppm) ([source](https://19january2017snapshot.epa.gov/ozone-pollution/2015-revision-2008-ozone-national-ambient-air-quality-standards-naaqs-supporting_.html)).\n",
        "\n",
        "Here, we want to test whether or not the state of Califronia (CA) meets the standard. For the purpose of this demonstration, we are going to loosen the \"4th highest daily maximum 8-hour ozone concentration per year\" assumption. Instead, we are going to see if the **average of the max O3 value across three years** meet the standards.\n",
        "\n",
        "**Resources**:\n",
        "- [How to filter by year](https://stackoverflow.com/questions/46878156/pandas-filter-dataframe-rows-with-a-specific-year)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### step 1: **data slicing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: let's subset the data together!\n",
        "# step 1: subset the data to get our desired output\n",
        "# note: here, we subset for \"O3 1st Max Value\",\n",
        "# but we can also use \"O3 Mean\" depending on our research question\n",
        "# 1a: subset the dataset, keeping California only, name it 'ca'\n",
        "ca = df[___]\n",
        "\n",
        "# 1b: subset 'ca' to keep data where year is after 2011 (inclusive), name it 'ca_2011'\n",
        "ca_2011 = ca[___]\n",
        "\n",
        "# 1c: subset 'ca_2011' to keep data where year is before 2013 (inclusive), name it 'ca_2011_2013'\n",
        "ca_2011_2013 = ca_2011[___]\n",
        "\n",
        "# 1d: last but not least, we can just keep the columns we want\n",
        "ca_2011_2013 = ca_2011_2013[['Date Local', 'O3 1st Max Value']]\n",
        "\n",
        "# alternatively, we can write all of this in one line!\n",
        "# ca_2011_2013 = df[(df['State'] == 'California') & ((df['Date Local'].dt.year >= 2011) & (df['Date Local'].dt.year <= 2013))][['Date Local','O3 1st Max Value']]\n",
        "\n",
        "# optional but highly recommended: rename columns for easier access\n",
        "ca_2011_2013 = ca_2011_2013.rename(columns={\"Date Local\": \"date\",\n",
        "                                            \"O3 1st Max Value\": \"o3\"})\n",
        "\n",
        "# always a good idea to check the data\n",
        "display(ca_2011_2013.head())\n",
        "\n",
        "# TODO: save file\n",
        "ca_2011_2013.to_csv(\"filename\")\n",
        "# if using Google colab:\n",
        "# from google.colab import files\n",
        "# files.download (\"filename\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJglzq5VoOwQ"
      },
      "source": [
        "#### step 2: **define hypotheses**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcfGQHpLoOwQ"
      },
      "source": [
        "Before we jump into data analysis, take a moment and formulate our null and alternative hypotheses:\n",
        "\n",
        "- Null hypothesis ($H_0$): The mean value of the average daily ozone concentration in CA is 0.07.\n",
        "\n",
        "- Alternative Hypothesis ($H_A$): The mean value of the average daily ozone concentration in CA is greater than 0.07."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LoynAAEoOwQ"
      },
      "source": [
        "#### step 3: **define $\\alpha$ (significance level)**\n",
        "\n",
        "Typically, $\\alpha$ is set to be 0.05."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### optional step: **data visualization**\n",
        "\n",
        "What does the null and alternative hypothesis mean?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters\n",
        "null_mean = 0.07\n",
        "sample_std = 0.015\n",
        "n = 1000\n",
        "\n",
        "# generate x values for the plot\n",
        "x = np.linspace(0.01, 0.13, 1000)\n",
        "\n",
        "# calculate the normal distribution PDF\n",
        "y = stats.norm.pdf(x, loc=null_mean, scale=sample_std)\n",
        "\n",
        "# declare the figure\n",
        "fig, ax = plt.subplots(1, 3, figsize=(20, 6), dpi = 400)\n",
        "\n",
        "# plot the null hypothesis distribution for all three graphs\n",
        "ax[0].plot(x, y, label='H₀ Distribution', color='olive')\n",
        "ax[1].plot(x, y, label='H₀ Distribution', color='olive')\n",
        "ax[2].plot(x, y, label='H₀ Distribution', color='olive')\n",
        "\n",
        "# === two tailed test ===\n",
        "# i.e., if HA is μ ≠ μ0\n",
        "lower_bound = stats.norm.ppf(0.025, loc=null_mean, scale=sample_std)\n",
        "upper_bound = stats.norm.ppf(0.975, loc=null_mean, scale=sample_std)\n",
        "\n",
        "# add vertical line for null hypothesis mean\n",
        "ax[0].axvline(x=null_mean, color='firebrick', linestyle='--', label='Null Mean (μ₀=0.07)')\n",
        "\n",
        "# fill in the rejection region (alpha = opacity)\n",
        "ax[0].fill_between(x, y, where=(x <= lower_bound) | (x >= upper_bound), color='darkgoldenrod', alpha=0.5)\n",
        "\n",
        "# add annotations for alternative hypothesis regions\n",
        "ax[0].annotate('rejection region', xy=(lower_bound-sample_std*0.7, 0.1*max(y)),\n",
        "             xytext=(lower_bound, 0.25*max(y)),\n",
        "             arrowprops=dict(facecolor='sienna', shrink=0.05),\n",
        "             ha='right')\n",
        "ax[0].annotate('rejection region', xy=(upper_bound+sample_std*0.7, 0.1*max(y)),\n",
        "             xytext=(upper_bound, 0.25*max(y)),\n",
        "             arrowprops=dict(facecolor='sienna', shrink=0.05),\n",
        "             ha='left')\n",
        "ax[0].legend(loc='best')\n",
        "ax[0].set_title('Two tailed test (HA: μ ≠ μ₀)')\n",
        "\n",
        "# === right tailed test ===\n",
        "# i.e., if HA is μ > μ0\n",
        "right_tail = stats.norm.ppf(0.95, loc=null_mean, scale=sample_std)\n",
        "\n",
        "# add vertical line for null hypothesis mean\n",
        "ax[1].axvline(x=null_mean, color='firebrick', linestyle='--', label='Null Mean (μ₀=0.07)')\n",
        "\n",
        "# fill in the rejection region (alpha = opacity)\n",
        "ax[1].fill_between(x, y, where=(x >= right_tail), color='darkgoldenrod', alpha=0.5)\n",
        "\n",
        "# add annotations for alternative hypothesis regions\n",
        "ax[1].annotate('rejection region', xy=(right_tail+sample_std*0.7, 0.15*max(y)),\n",
        "             xytext=(right_tail, 0.3*max(y)),\n",
        "             arrowprops=dict(facecolor='sienna', shrink=0.05),\n",
        "             ha='left')\n",
        "ax[1].legend(loc='best')\n",
        "ax[1].set_title('Right tailed test (HA: μ > μ₀)')\n",
        "\n",
        "# === left tailed test ===\n",
        "# i.e., if HA is μ < μ0\n",
        "left_tail = stats.norm.ppf(0.05, loc=null_mean, scale=sample_std)\n",
        "\n",
        "# add vertical line for null hypothesis mean\n",
        "ax[2].axvline(x=null_mean, color='firebrick', linestyle='--', label='Null Mean (μ₀=0.07)')\n",
        "\n",
        "# fill in the rejection region (alpha = opacity)\n",
        "ax[2].fill_between(x, y, where=(x <= left_tail), color='darkgoldenrod', alpha=0.5)\n",
        "\n",
        "# add annotations for alternative hypothesis regions\n",
        "ax[2].annotate('rejection region', xy=(left_tail-sample_std*0.7, 0.15*max(y)),\n",
        "             xytext=(left_tail, 0.3*max(y)),\n",
        "             arrowprops=dict(facecolor='sienna', shrink=0.05),\n",
        "             ha='right')\n",
        "ax[2].legend(loc='best')\n",
        "ax[2].set_title('Left tailed test (HA: μ < μ₀)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intuitively, will we be able to reject the null?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# first, declare the figure\n",
        "fig, ax = plt.subplots(1, 1, figsize=(16, 4), dpi=400)\n",
        "plt.tight_layout(pad=3.0)\n",
        "\n",
        "# next, plot with Seaborn\n",
        "sns.histplot(x=\"o3\", \n",
        "             data=ca_2011_2013, \n",
        "             label = \"O3 1st Max Value\",\n",
        "             ax=ax)\n",
        "\n",
        "# don't forget to set labels and titles\n",
        "ax.set_xlabel(\"Ozone 1st max value\")\n",
        "ax.set_ylabel(\"Frequency count\")\n",
        "ax.set_title(\"Distribution of Ozone in California, 2011-2013\", fontsize = 14)\n",
        "\n",
        "# additional labels\n",
        "threshold = 0.07\n",
        "ci_higher = ca_2011_2013.o3.quantile(0.95)\n",
        "ax.axvline(x=threshold, linewidth=2, color='r', label = \"threshold\")\n",
        "ax.axvline(x=ci_higher, linewidth=2, color='b', label = \"confidence interval\")\n",
        "plt.legend(loc=0)\n",
        "# save figure\n",
        "plt.savefig(\"figures/ci_and_h0.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the visualization, do you think we can reject the null? Why or why not? What does your intuition tell you? \n",
        "\n",
        "NOTE: We still have to do the actual analysis!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYEgDgLooOwQ"
      },
      "source": [
        "#### step 4: **check assumptions**\n",
        "\n",
        "Usually in t-tests, there are several assumptions that should be followed:\n",
        "- Independence of samples: samples should be randomly selected\n",
        "- Identically Distributed: samples should come from the same distribution\n",
        "- Normality (or sample size >30): samples should be normally distributed (Q-Q plots)\n",
        "- Equal variances: samples should have equal variances (box plots)\n",
        "\n",
        "In our example, we are conducting a one-sample t-test, so only the first assumption applies. However, due to the nature of our data being collected over time, we are going to loosen the assumption that time has an effect on ground Ozone levels.\n",
        "\n",
        "Resources:\n",
        "- [Tutorial on t-tests](https://www.datacamp.com/tutorial/an-introduction-to-python-t-tests)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-ZhATMoOwQ"
      },
      "source": [
        "#### optional step: **data visualization**\n",
        "\n",
        "As seen earlier in the workshop, visualizations can be powerful! Here, we demonstrate some ways we can create visualizations for this question. You can find a section in the end of this note book for skeleton code used for plotting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "NqKAUh1IoOwQ",
        "outputId": "e9fd9a38-d807-4115-d1b7-019ecd89471f"
      },
      "outputs": [],
      "source": [
        "# TODO: live coding!\n",
        "# for our question, we can plot...\n",
        "# (1) histogram to see the distribution - directly related to hypothesis testing\n",
        "# (2) scatterplot to see dates with O3 values that exceed the standard\n",
        "\n",
        "# first, declare the figure\n",
        "# syntax: fig, ax = plt.subplots(nrow, ncol, figsize=(width, height), dpi=dots_per_inch)\n",
        "fig, ax = plt.subplots(2, 1, figsize=(16, 8), dpi=400)\n",
        "\n",
        "# padding determines the margin between your graphs\n",
        "# think: what would it look like if pad = 1.0? try it yourself!\n",
        "plt.tight_layout(pad=4.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfeT4aq8GtBU",
        "outputId": "4978af1f-91cf-45a2-e72e-a987e33eb206"
      },
      "outputs": [],
      "source": [
        "# imagine you are \"storing\" your visual in the axes!\n",
        "print(ax)\n",
        "print(len(ax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "HPiVIZ0qAbcr",
        "outputId": "128c5158-550b-449b-f3e0-f2530cb83907"
      },
      "outputs": [],
      "source": [
        "# *full* pipeline\n",
        "# first, declare the figure\n",
        "# syntax: fig, ax = plt.subplots(nrow, ncol, figsize=(width, height), dpi=dots_per_inch)\n",
        "fig, ax = plt.subplots(2, 1, figsize=(16, 8), dpi=400)\n",
        "plt.tight_layout(pad=4.0)\n",
        "\n",
        "# next, plot with Seaborn\n",
        "# (1) histogram to see the distribution - directly related to hypothesis testing\n",
        "# (2) scatterplot to see dates with O3 values that exceed the standard\n",
        "# first plot: ax[0] want to see distribution of o3\n",
        "sns.___(x=\"o3\",\n",
        "             data=ca_2011_2013,\n",
        "             label = \"O3 1st Max Value\",\n",
        "             ax=ax[0])\n",
        "\n",
        "# second plot: ax[1] want to dates with O3 values that exceed the standard (0.07)\n",
        "# step 1: plot scatter plot\n",
        "# what should the x and y axis be? remember, we want to see what O3 values look over \"time\"\n",
        "sns.___(x=\"___\",\n",
        "                y=\"___\",\n",
        "                data=ca_2011_2013,\n",
        "                label=\"___\", # what do we want the legend to say?\n",
        "                ax=ax[1])\n",
        "\n",
        "# step 2: we want to \"overlay\" a scatterplot to highlight the points where O3 value > threshold\n",
        "sns.___(x=\"___\",\n",
        "                y=\"___\",\n",
        "                data=ca_2011_2013[ca_2011_2013['o3']>0.07],\n",
        "                label=\"Above threshold\",\n",
        "                color = 'r',\n",
        "                ax=ax[1])\n",
        "\n",
        "# don't forget to set labels and titles\n",
        "ax[0].set_xlabel(\"Ozone 1st max value\")\n",
        "ax[0].set_ylabel(\"Frequency count\")\n",
        "ax[0].set_title(\"Distribution of Ozone in California, 2011-2013\",\n",
        "                fontsize = 16)\n",
        "\n",
        "ax[1].set_xlabel(\"Date\")\n",
        "ax[1].set_ylabel(\"Ozone 1st max value\")\n",
        "ax[1].set_title(\"Ozone Levels in California (2011-2013): Daily Observations with Exceedances Highlighted\",\n",
        "                fontsize = 16)\n",
        "\n",
        "# additional annotations\n",
        "# some variables we might need later\n",
        "threshold = 0.07\n",
        "mean_o3 = ca_2011_2013['o3'].mean()\n",
        "# for the histogram, let's try to annotate the following:\n",
        "# (a) a vertical line to show the EPA threshold\n",
        "ax[0].___(x=0.07, linewidth=3, color='r', label = \"threshold\")\n",
        "\n",
        "# (b) a vertical line to show the mean of the O3\n",
        "ax[0].___(x=ca_2011_2013['o3'].mean(), linewidth=3, color='b', label = \"mean\")\n",
        "\n",
        "# important line, shows the legend\n",
        "ax[0].legend(loc=0, fontsize=14)\n",
        "\n",
        "# for the scatter plot, what do we want to annotate?\n",
        "_____\n",
        "\n",
        "# optional: add caption\n",
        "# caption = \"your caption here\"\n",
        "# fig.text(x, y, caption, ha='center')\n",
        "\n",
        "# TODO: change filename\n",
        "# save figure\n",
        "plt.savefig(\"filename\")\n",
        "# if using Google colab:\n",
        "# from google.colab import files\n",
        "# files.download (\"filename\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0g2otlboOwQ"
      },
      "source": [
        "#### step 5: **statistical testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0vZXHXLoOwQ"
      },
      "outputs": [],
      "source": [
        "# import 1 sample t-test from scipy\n",
        "from scipy.stats import t\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# peform one-tailed one-sample t-test\n",
        "x = ca_2011_2013['o3']\n",
        "t_stat, p_value = ttest_1samp(a = x,\n",
        "                              popmean = 0.070,\n",
        "                              alternative=\"greater\")\n",
        "print(f\"One-sample t-Test results: \\nt-statistic = {t_stat:0.3f} \\np-value = {p_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA_zSu_cJklw"
      },
      "outputs": [],
      "source": [
        "# what if we delete the alternative?\n",
        "t_stat, p_value = ttest_1samp(a = x,\n",
        "                              popmean = 0.070)\n",
        "print(f\"One-sample t-Test results: \\nt-statistic = {t_stat:0.3f} \\np-value = {p_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQhihz_3JpTs"
      },
      "outputs": [],
      "source": [
        "# what if we change the alternative to \"less\"?\n",
        "t_stat, p_value = ttest_1samp(a = x,\n",
        "                              popmean = 0.070,\n",
        "                              alternative=\"less\")\n",
        "print(f\"One-sample t-Test results: \\nt-statistic = {t_stat:0.3f} \\np-value = {p_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "tNM75SLvoOwQ",
        "outputId": "0dd0d4d8-95b1-4a89-abca-fefe77e44347"
      },
      "outputs": [],
      "source": [
        "x = ca_2011_2013['o3']\n",
        "dof = len(x) - 1\n",
        "x_axis = np.linspace(-5, 5, 100)\n",
        "y = t.pdf(x_axis, dof)\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "# Calculate the critical t-value for the right-tailed test\n",
        "# identical to: critical_value = t.ppf(q = 0.95, df = dof)\n",
        "critical_value = t.ppf(q = 1 - alpha, df = dof)\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 4), dpi=200)\n",
        "plt.plot(x_axis, y, label='t-distribution', color='olive')\n",
        "\n",
        "# Shade the rejection region\n",
        "x_fill = np.linspace(critical_value, 5, 100)\n",
        "y_fill = t.pdf(x_fill, dof)\n",
        "plt.fill_between(x_fill, y_fill, color='khaki', alpha=0.5, label='Rejection Region')\n",
        "\n",
        "# Add a vertical line at the critical value\n",
        "plt.axvline(x=critical_value, color='darkgoldenrod', linestyle='--', label=f'Critical Value (t={critical_value:.2f})')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('t-Distribution with Rejection Region for Right-Tailed Test')\n",
        "plt.xlabel('t-value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obWKVzkyoOwQ"
      },
      "source": [
        "#### step 6: **statistical testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9zIbuEhdoOwQ"
      },
      "outputs": [],
      "source": [
        "# TODO: Write your conclusion in the Markdown box below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCD4E7HZoOwQ"
      },
      "source": [
        "(your conclusion here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sGppfhWoOwQ"
      },
      "source": [
        "#### **IMPORTANT NOTE**:\n",
        "There are several variations to the t-test, such as two-sample t-tests (student's t-test and Welch's t-test for unequal variance). The most important skill here for research is:\n",
        "1. Look at your data and formulate a research question.\n",
        "2. Decide the most appropriate statistical test to apply.\n",
        "\n",
        "If you ever have doubts, always ask! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pac0GVzKoOwR"
      },
      "source": [
        "# Appendix 1. Visualization Recipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xq9ny54oOwR"
      },
      "source": [
        "Below is a skeleton code for visualizing with Seaborn and Matplotlib, but this is NOT meant for you to follow the format stringently.\n",
        "```\n",
        "# skeleton code for plotting in python\n",
        "\n",
        "# first, declare the figure\n",
        "fig, ax = plt.subplots(n_row, n_col, figsize = (width, height), dpi = 400)\n",
        "\n",
        "# next, plot with Seaborn\n",
        "# note: change the ax=ax[i] argument if you have multiple subplots\n",
        "sns.histplot(x=iv, data=data, ax=ax)\n",
        "sns.lineplot(x=iv, y=dv, data=data, label=\"legend label\", ax=ax)\n",
        "sns.barplot(x=iv, y=dv, data=data, ax=ax)\n",
        "\n",
        "# don't forget to set labels and titles\n",
        "# similarly, change ax to ax[i] if you have multiple subplots\n",
        "ax.set_xlabel(\"your xlabel here\")\n",
        "ax.set_ylabel(\"your ylabel here\")\n",
        "ax.set_title(\"your title here\")\n",
        "\n",
        "# optional: add caption\n",
        "# similarly, change ax to ax[i] if you have multiple subplots\n",
        "caption = \"your caption here\"\n",
        "ax.text(x, y, caption, ha='center')\n",
        "\n",
        "# save figure\n",
        "plt.savefig(\"filename.png\")\n",
        "# if using Google colab:\n",
        "files.download(\"filename.png\")\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "barnard-cf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
